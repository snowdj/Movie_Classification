{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prototype Naive Bayes on TMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "tmdb_genres_list = pickle.load(open('data/tmdb_genres_list.pkl', \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pickle.load(open('data/tmdb_processed.pkl', \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies[130973:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = len(tmdb_genres_list)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = np.array([m['title'] for m in movies])\n",
    "plots = np.array([m['overview'] for m in movies])\n",
    "genres = np.array([m['genre_ids'] for m in movies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_df=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.random.choice(len(plots), replace=False, size=int(len(plots)*0.8))\n",
    "test_idx = set(range(len(plots))) - set(train_idx)\n",
    "test_idx = np.array(list(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = cv.fit_transform(plots[train_idx])\n",
    "X_test = cv.transform(plots[test_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb=MultiLabelBinarizer()\n",
    "Y=mlb.fit_transform(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y[train_idx]\n",
    "Y_test = Y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<24000x56241 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1056188 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(gt,preds):\n",
    "    TP=0\n",
    "    FP=0\n",
    "    FN=0\n",
    "    for i in range(len(gt)):\n",
    "        if gt[i] ==1 and preds[i] == 1:\n",
    "            TP+=1\n",
    "        elif gt[i] ==0 and preds[i] == 1:\n",
    "            FN+=1\n",
    "        elif gt[i] ==1 and preds[i] == 0:\n",
    "            FP+=1\n",
    "    if TP+FP==0:\n",
    "        precision=0\n",
    "    else:\n",
    "        precision=TP/float(TP+FP)\n",
    "    if TP+FN==0:\n",
    "        recall=0\n",
    "    else:\n",
    "        recall=TP/float(TP+FN)\n",
    "    if TP + FP + FN == 0:\n",
    "        f1 = 0\n",
    "    else:\n",
    "        f1 = 2 * TP / float(2 * TP + FP + FN)\n",
    "    return precision,recall,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_loss(gt, preds):\n",
    "    err = 0\n",
    "    for i in range(len(gt)):\n",
    "        if (gt[i] ==0 and preds[i] == 1) or (gt[i] ==1 and preds[i] == 0):\n",
    "            err +=1\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, LabelPowerset = False, tfidf=False):\n",
    "    if tfidf:\n",
    "        X_tr = X_train_tfidf\n",
    "        X_te = X_test_tfidf\n",
    "    else:\n",
    "        X_tr = X_train\n",
    "        X_te = X_test\n",
    "    \n",
    "    model.fit(X_tr, Y_train)\n",
    "#     train_acc = model.score(X_tr,Y_train)\n",
    "#     test_acc = model.score(X_te,Y_test)\n",
    "    \n",
    "    if LabelPowerset:\n",
    "        train_pred = model.predict(X_tr).toarray()\n",
    "        test_pred = model.predict(X_te).toarray()\n",
    "    else:\n",
    "        train_pred = model.predict(X_tr)\n",
    "        test_pred = model.predict(X_te)\n",
    "        \n",
    "    train_precs=[]\n",
    "    train_recs=[]\n",
    "    test_precs=[]\n",
    "    test_recs=[]\n",
    "    train_f1=[]\n",
    "    test_f1=[]\n",
    "#     train_h_loss = []\n",
    "#     test_h_loss = []\n",
    "    \n",
    "    for i in range(len(Y_test)):\n",
    "        a,b,c=precision_recall(Y_train[i],train_pred[i])\n",
    "        train_precs.append(a)\n",
    "        train_recs.append(b)\n",
    "        train_f1.append(c)\n",
    "        a,b,c=precision_recall(Y_test[i],test_pred[i])\n",
    "        test_precs.append(a)\n",
    "        test_recs.append(b)\n",
    "        test_f1.append(c)\n",
    "#         train_h_loss.append(hamming_loss(Y_train[i],train_pred[i]))\n",
    "#         test_h_loss.append(hamming_loss(Y_test[i],test_pred[i]))\n",
    "    \n",
    "    #print(\"Acc: {} (train)   {} (test)\".format(train_acc, test_acc))\n",
    "    print(\" Training Precision:{} Recall :{} f1 score:{}\" .format(np.mean(np.asarray(train_precs)), np.mean(np.asarray(train_recs)), np.mean(np.asarray(train_f1))))\n",
    "    print(\" Test Precision:{} Recall :{} f1 score:{}\" .format(np.mean(np.asarray(test_precs)), np.mean(np.asarray(test_recs)), np.mean(np.asarray(test_f1))))\n",
    "    #print(\" Training Hamming Loss:{} Test Hamming Loss :{}\" .format(np.mean(np.asarray(train_h_loss)/k), np.mean(np.asarray(test_h_loss)/k)))\n",
    "    \n",
    "    \n",
    "    #print(\"F1: {} (train)   {} (test)\".format(train_f1, test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = OneVsRestClassifier(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Precision:0.5067916666666666 Recall :0.5699949613295202 f1 score:0.5156456543456543\n",
      " Test Precision:0.3336126984126984 Recall :0.3969970492470493 f1 score:0.3467642292004521\n"
     ]
    }
   ],
   "source": [
    "evaluate(nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Precision:0.0266 Recall :0.035166666666666666 f1 score:0.029066666666666664\n",
      " Test Precision:0.0036805555555555554 Recall :0.005666666666666667 f1 score:0.004261111111111111\n"
     ]
    }
   ],
   "source": [
    "evaluate(nb, tfidf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Precision:0.3378388888888889 Recall :0.4088333333333333 f1 score:0.358734126984127\n",
      " Test Precision:0.26737222222222223 Recall :0.3411666666666667 f1 score:0.28920317460317463\n"
     ]
    }
   ],
   "source": [
    "nb2 = LabelPowerset(MultinomialNB())\n",
    "evaluate(nb2, LabelPowerset= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(nb2, LabelPowerset=True, tfidf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = OneVsRestClassifier(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Precision:0.07410833333333332 Recall :0.0885\n"
     ]
    }
   ],
   "source": [
    "evaluate(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Precision:0.08425 Recall :0.106\n"
     ]
    }
   ],
   "source": [
    "evaluate(rf, tfidf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = OneVsRestClassifier(LinearSVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Precision:0.8165 Recall :0.8167083333333334 f1 score:0.8165428571428571\n",
      " Test Precision:0.41566587301587304 Recall :0.4220027777777777 f1 score:0.400118253968254\n"
     ]
    }
   ],
   "source": [
    "evaluate(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Precision:0.7553083333333334 Recall :0.7869305555555557 f1 score:0.7652718133718136\n",
      " Test Precision:0.3739638888888889 Recall :0.43115277777777783 f1 score:0.3861771645021645\n"
     ]
    }
   ],
   "source": [
    "evaluate(svm, tfidf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm2 = LabelPowerset(LinearSVC())\n",
    "evaluate(svm2, LabelPowerset=True)\n",
    "evaluate(svm2, LabelPowerset=True, tfidf= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "parameters = {'kernel':['linear'], 'C':[0.01, 0.1, 1.0]}\n",
    "gridCV = GridSearchCV(SVC(class_weight='balanced'), parameters, scoring=make_scorer(f1_score, average='micro'))\n",
    "classif = OneVsRestClassifier(gridCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(classif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = OneVsRestClassifier(LogisticRegressionCV())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Precision:0.6572777777777777 Recall :0.7179444444444444\n",
      " Test Precision:0.35959444444444444 Recall :0.4159555555555555\n",
      " Training Hamming Loss:0.018359649122807017 Test Hamming Loss :0.059219298245614026\n"
     ]
    }
   ],
   "source": [
    "evaluate(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
