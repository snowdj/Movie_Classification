{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from vocab import Vocab, load_vocab\n",
    "from common import Data, Split, Batches, load_data, encode_y, load_split\n",
    "from utils import ProgressBar, evaluate\n",
    "from pack import Pack\n",
    "from model import Model, Model2, TextOnlyModel\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = pickle.load(open(\"../data/tmdb_genres_list.pkl\", 'rb'))\n",
    "\n",
    "GENRES = load_data(\"../local/genres.pkl\")\n",
    "train = load_split(\"../local/train.pkl\")\n",
    "val = load_split(\"../local/val.pkl\")\n",
    "test = load_split(\"../local/test.pkl\")\n",
    "embedding = torch.load('../local/embedding.pth')\n",
    "OVERVIEWS_ENCODED = load_data(\"../local/overviews_encoded.pkl\")\n",
    "TITLES_ENCODED = load_data(\"../local/titles_encoded.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_model = Model2(embedding, hidden_dim=512, num_layers=3, cuda=True)\n",
    "tomodel = TextOnlyModel(_model.encoder, _model.classifier, OVERVIEWS_ENCODED, GENRES)\n",
    "loss = torch.nn.BCEWithLogitsLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batches(model:Model, batch_size:int, display:bool=True):\n",
    "    losses = []\n",
    "\n",
    "    batches = Batches(train, batch_size)\n",
    "\n",
    "    pb = ProgressBar(batches.batch_N, display=display)\n",
    "\n",
    "    train.shuffle()\n",
    "    pb.reset()\n",
    "    for i in range(batches.batch_N):\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_true = model.get_y(batches, i)\n",
    "        y_true = torch.autograd.Variable(torch.from_numpy(y_true)).cuda().type(torch.cuda.FloatTensor)\n",
    "        model_output = model.predict(batches, i)\n",
    "\n",
    "        l = loss(model_output, y_true)\n",
    "        l.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(l.data.cpu().numpy()[0])\n",
    "\n",
    "        pb.tick()\n",
    "        \n",
    "    return losses\n",
    "\n",
    "def train_epoches(model:Model, n_epochs:int, batch_size:int):\n",
    "    epoch_losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        losses = train_batches(model, batch_size, display=False)\n",
    "        epoch_losses.append(losses)\n",
    "        print(\"epoch {}:\".format(epoch), np.mean(losses))\n",
    "        print(\"Train:\", end=\"\\t\")\n",
    "        evaluate(train, model, batch_size)\n",
    "        print(\"Val:\", end=\"\\t\")\n",
    "        evaluate(val, model, batch_size)\n",
    "    return epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad, _model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: 0.29861966\n",
      "Train:\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongxiangqiu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/hongxiangqiu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P 0.0 \tR: 0.0 \tF1: 0.0\n",
      "Val:\tP 0.0 \tR: 0.0 \tF1: 0.0\n",
      "epoch 1: 0.2325613\n",
      "Train:\tP 0.0002150471567693773 \tR: 0.5384615384615384 \tF1: 0.0004299226139294927\n",
      "Val:\tP 0.00048828125 \tR: 1.0 \tF1: 0.0009760858955588092\n",
      "epoch 2: 0.2181127\n",
      "Train:\tP 0.0022119136124850234 \tR: 0.5625 \tF1: 0.004406499586890663\n",
      "Val:\tP 0.002685546875 \tR: 0.5238095238095238 \tF1: 0.005343696866650473\n",
      "epoch 3: 0.21074232\n",
      "Train:\tP 0.010107216368160732 \tR: 0.5264 \tF1: 0.019833614661200868\n",
      "Val:\tP 0.00830078125 \tR: 0.5074626865671642 \tF1: 0.01633437424933942\n",
      "epoch 4: 0.20542252\n",
      "Train:\tP 0.03852416208411416 \tR: 0.616519174041298 \tF1: 0.07251698713315022\n",
      "Val:\tP 0.03271484375 \tR: 0.5851528384279476 \tF1: 0.06196531791907514\n",
      "epoch 5: 0.19967698\n",
      "Train:\tP 0.06122699763448128 \tR: 0.6228125 \tF1: 0.11149338480042517\n",
      "Val:\tP 0.054443359375 \tR: 0.5883905013192612 \tF1: 0.09966480446927375\n",
      "epoch 6: 0.19395664\n",
      "Train:\tP 0.12091794414918128 \tR: 0.5664939550949913 \tF1: 0.19929618471353702\n",
      "Val:\tP 0.112060546875 \tR: 0.5563636363636364 \tF1: 0.18654744970534443\n",
      "epoch 7: 0.18846714\n",
      "Train:\tP 0.13953488372093023 \tR: 0.5904068633822956 \tF1: 0.22572308915614747\n",
      "Val:\tP 0.127197265625 \tR: 0.5596133190118152 \tF1: 0.20728068430475433\n",
      "epoch 8: 0.18294732\n",
      "Train:\tP 0.21642960277718043 \tR: 0.5823276574640437 \tF1: 0.3155725772133755\n",
      "Val:\tP 0.189453125 \tR: 0.5340674466620785 \tF1: 0.2796900342404037\n",
      "epoch 9: 0.17885755\n",
      "Train:\tP 0.24389419679886948 \tR: 0.5799123447772097 \tF1: 0.3433749270128241\n",
      "Val:\tP 0.20751953125 \tR: 0.5117399157134257 \tF1: 0.2952926871634532\n",
      "epoch 10: 0.17267008\n",
      "Train:\tP 0.23596817302079814 \tR: 0.6168982411051321 \tF1: 0.3413626061063953\n",
      "Val:\tP 0.18408203125 \tR: 0.5313601127554616 \tF1: 0.27343608340888487\n",
      "epoch 11: 0.16523637\n",
      "Train:\tP 0.2643543977143559 \tR: 0.6536270413976453 \tF1: 0.37645463295126436\n",
      "Val:\tP 0.206787109375 \tR: 0.5587071240105541 \tF1: 0.30185317177476834\n",
      "epoch 12: 0.15834527\n",
      "Train:\tP 0.2926177383183312 \tR: 0.6777912189568064 \tF1: 0.40876319629216373\n",
      "Val:\tP 0.205322265625 \tR: 0.5326155794806839 \tF1: 0.2963876651982379\n",
      "epoch 13: 0.15061484\n",
      "Train:\tP 0.3635525790298301 \tR: 0.700278122965856 \tF1: 0.4786248736097068\n",
      "Val:\tP 0.257568359375 \tR: 0.5407483341875962 \tF1: 0.3489333553828345\n",
      "epoch 14: 0.14226024\n",
      "Train:\tP 0.38118644588491907 \tR: 0.7467950647005718 \tF1: 0.504739047309116\n",
      "Val:\tP 0.255615234375 \tR: 0.5740131578947368 \tF1: 0.35371621621621624\n",
      "epoch 15: 0.13411413\n",
      "Train:\tP 0.43135387545697523 \tR: 0.7733105689265848 \tF1: 0.5537982172438275\n",
      "Val:\tP 0.277587890625 \tR: 0.568784392196098 \tF1: 0.3730926989335521\n",
      "epoch 16: 0.12625411\n",
      "Train:\tP 0.5237627108230162 \tR: 0.7741100617508173 \tF1: 0.6247915712322492\n",
      "Val:\tP 0.332275390625 \tR: 0.5435303514376997 \tF1: 0.4124242424242424\n",
      "epoch 17: 0.11823979\n",
      "Train:\tP 0.5456053577463058 \tR: 0.7769708635926152 \tF1: 0.6410510927827608\n",
      "Val:\tP 0.34716796875 \tR: 0.5417142857142857 \tF1: 0.42315131676833806\n",
      "epoch 18: 0.11320933\n",
      "Train:\tP 0.5921477066756782 \tR: 0.7804907677356657 \tF1: 0.6733977326322778\n",
      "Val:\tP 0.3740234375 \tR: 0.5337979094076655 \tF1: 0.4398507034165949\n",
      "epoch 19: 0.10693076\n",
      "Train:\tP 0.5859420601517619 \tR: 0.854180661919477 \tF1: 0.6950801749271137\n",
      "Val:\tP 0.326416015625 \tR: 0.5533940397350994 \tF1: 0.41062653562653567\n",
      "epoch 0: 0.09571267\n",
      "Train:\tP 0.6468618475622868 \tR: 0.8514010755731672 \tF1: 0.7351698613875213\n",
      "Val:\tP 0.361328125 \tR: 0.5360376675117711 \tF1: 0.4316756599095814\n",
      "epoch 1: 0.088940926\n",
      "Train:\tP 0.6912844459463611 \tR: 0.8587566309201237 \tF1: 0.7659733805357933\n",
      "Val:\tP 0.390869140625 \tR: 0.5287318361955086 \tF1: 0.4494665918023582\n",
      "epoch 2: 0.08479435\n",
      "Train:\tP 0.6900863260729317 \tR: 0.8419099733893033 \tF1: 0.7584751485683415\n",
      "Val:\tP 0.398681640625 \tR: 0.5322685788787483 \tF1: 0.4558905639307649\n",
      "epoch 3: 0.080364764\n",
      "Train:\tP 0.7272894841940339 \tR: 0.8881968935244241 \tF1: 0.7997297525546829\n",
      "Val:\tP 0.3916015625 \tR: 0.5474402730375426 \tF1: 0.4565898092798178\n",
      "epoch 4: 0.07111506\n",
      "Train:\tP 0.7686399803385456 \tR: 0.8863853757041131 \tF1: 0.8233242291618679\n",
      "Val:\tP 0.41064453125 \tR: 0.5176977531548169 \tF1: 0.45799863852961203\n",
      "epoch 5: 0.06609707\n",
      "Train:\tP 0.8047064606310098 \tR: 0.8761121145227105 \tF1: 0.8388925363096287\n",
      "Val:\tP 0.438720703125 \tR: 0.5073404856013551 \tF1: 0.47054202670856243\n",
      "epoch 6: 0.06180964\n",
      "Train:\tP 0.7740776013025713 \tR: 0.9057153127246586 \tF1: 0.8347385334017988\n",
      "Val:\tP 0.395263671875 \tR: 0.5296041871115472 \tF1: 0.4526771983783028\n",
      "epoch 7: 0.060758468\n",
      "Train:\tP 0.7886393659180978 \tR: 0.9073269006468031 \tF1: 0.8438301229373479\n",
      "Val:\tP 0.4111328125 \tR: 0.5414790996784566 \tF1: 0.46738828753816264\n",
      "epoch 8: 0.059279207\n",
      "Train:\tP 0.819606156492888 \tR: 0.9008306320907618 \tF1: 0.8583010278765261\n",
      "Val:\tP 0.427978515625 \tR: 0.5175671685857691 \tF1: 0.46852866497394097\n",
      "epoch 9: 0.055502128\n",
      "Train:\tP 0.8090688458111885 \tR: 0.9212256891003218 \tF1: 0.8615122916632589\n",
      "Val:\tP 0.417724609375 \tR: 0.5262996001230391 \tF1: 0.46576834081938207\n",
      "epoch 10: 0.05333715\n",
      "Train:\tP 0.8408036619458695 \tR: 0.9082431804606093 \tF1: 0.8732232591529074\n",
      "Val:\tP 0.44921875 \tR: 0.5203619909502263 \tF1: 0.48218029350104824\n",
      "epoch 11: 0.05090011\n",
      "Train:\tP 0.8511566464931953 \tR: 0.9240261472785486 \tF1: 0.8860957863596387\n",
      "Val:\tP 0.42626953125 \tR: 0.5274924471299094 \tF1: 0.47150958682149613\n",
      "epoch 12: 0.04789972\n",
      "Train:\tP 0.8651654327056004 \tR: 0.9040190035952748 \tF1: 0.8841655808988589\n",
      "Val:\tP 0.4521484375 \tR: 0.5106148331954784 \tF1: 0.47960637058138034\n",
      "epoch 13: 0.04473903\n",
      "Train:\tP 0.8356425301834045 \tR: 0.9319240783883788 \tF1: 0.8811610165373589\n",
      "Val:\tP 0.406982421875 \tR: 0.5363577863577863 \tF1: 0.4627984453081621\n",
      "epoch 14: 0.045683257\n",
      "Train:\tP 0.8712789161623299 \tR: 0.9232697441239665 \tF1: 0.8965212031168502\n",
      "Val:\tP 0.440673828125 \tR: 0.5146849158825206 \tF1: 0.4748125739839537\n",
      "epoch 15: 0.044374656\n",
      "Train:\tP 0.8818776688888206 \tR: 0.9245088566827697 \tF1: 0.9026902092734391\n",
      "Val:\tP 0.4404296875 \tR: 0.5110481586402267 \tF1: 0.4731182795698925\n",
      "epoch 16: 0.04008191\n",
      "Train:\tP 0.8983748579152714 \tR: 0.9350578755515764 \tF1: 0.9163493928711319\n",
      "Val:\tP 0.4326171875 \tR: 0.5233313644418193 \tF1: 0.47367014167334937\n",
      "epoch 17: 0.03607812\n",
      "Train:\tP 0.8979754846241282 \tR: 0.935330069437778 \tF1: 0.9162722171718755\n",
      "Val:\tP 0.459716796875 \tR: 0.526565995525727 \tF1: 0.4908759124087591\n",
      "epoch 18: 0.03541029\n",
      "Train:\tP 0.914226905471414 \tR: 0.9325624392842593 \tF1: 0.9233036517638298\n",
      "Val:\tP 0.46337890625 \tR: 0.5133892345144712 \tF1: 0.48710381111253687\n",
      "epoch 19: 0.035779532\n",
      "Train:\tP 0.9180977542932629 \tR: 0.9467165077454304 \tF1: 0.9321875292429582\n",
      "Val:\tP 0.445556640625 \tR: 0.5151001975726786 \tF1: 0.4778112318366278\n",
      "epoch 0: 0.031809248\n",
      "Train:\tP 0.9178827071364934 \tR: 0.9534720449323462 \tF1: 0.9353389578474494\n",
      "Val:\tP 0.454345703125 \tR: 0.5294452347083926 \tF1: 0.48902903692024696\n",
      "epoch 1: 0.031478252\n",
      "Train:\tP 0.9247642161531135 \tR: 0.9484828433689385 \tF1: 0.9364733698357391\n",
      "Val:\tP 0.462890625 \tR: 0.5135427952329361 \tF1: 0.4869029275808937\n",
      "epoch 2: 0.029632207\n",
      "Train:\tP 0.9054099720438696 \tR: 0.9582832059827671 \tF1: 0.9310965785233628\n",
      "Val:\tP 0.418212890625 \tR: 0.5385099025463691 \tF1: 0.47079840593651234\n",
      "epoch 3: 0.029426506\n",
      "Train:\tP 0.9193573162114835 \tR: 0.95090718439198 \tF1: 0.934866139764456\n",
      "Val:\tP 0.444091796875 \tR: 0.5326500732064422 \tF1: 0.4843562774597257\n",
      "epoch 4: 0.027297724\n",
      "Train:\tP 0.9433197136800713 \tR: 0.9526261905500574 \tF1: 0.9479501111385528\n",
      "Val:\tP 0.48291015625 \tR: 0.5144343302990897 \tF1: 0.49817403349704065\n",
      "epoch 5: 0.025877478\n",
      "Train:\tP 0.9304783263186999 \tR: 0.9569970615185314 \tF1: 0.9435514018691589\n",
      "Val:\tP 0.4482421875 \tR: 0.5280414150129422 \tF1: 0.4848804965007263\n",
      "epoch 6: 0.025850222\n",
      "Train:\tP 0.9293416484900617 \tR: 0.9584930768987041 \tF1: 0.9436922884951335\n",
      "Val:\tP 0.446044921875 \tR: 0.5345231129315389 \tF1: 0.4862922544583444\n",
      "epoch 7: 0.02559172\n",
      "Train:\tP 0.9389266074774969 \tR: 0.9666329306091467 \tF1: 0.9525783478003398\n",
      "Val:\tP 0.455078125 \tR: 0.540446506233691 \tF1: 0.494102054340623\n",
      "epoch 8: 0.023172978\n",
      "Train:\tP 0.9511535743909557 \tR: 0.970716413230914 \tF1: 0.9608354281103559\n",
      "Val:\tP 0.4453125 \tR: 0.5277777777777778 \tF1: 0.48305084745762716\n",
      "epoch 9: 0.021296281\n",
      "Train:\tP 0.9381585819176063 \tR: 0.9753433407856915 \tF1: 0.956389658790185\n",
      "Val:\tP 0.42822265625 \tR: 0.552093169656909 \tF1: 0.4823319125532793\n",
      "epoch 10: 0.022699982\n",
      "Train:\tP 0.9519830419956377 \tR: 0.9597076403728824 \tF1: 0.9558297347316472\n",
      "Val:\tP 0.477783203125 \tR: 0.5129750982961993 \tF1: 0.4947541398053344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11: 0.022481171\n",
      "Train:\tP 0.9546557709440571 \tR: 0.972369985606108 \tF1: 0.963431459176239\n",
      "Val:\tP 0.443115234375 \tR: 0.5266976204294834 \tF1: 0.48130469371519485\n",
      "epoch 12: 0.01999401\n",
      "Train:\tP 0.9572363368252895 \tR: 0.963809582727582 \tF1: 0.9605117139334155\n",
      "Val:\tP 0.46923828125 \tR: 0.5188984881209503 \tF1: 0.4928205128205128\n",
      "epoch 13: 0.020063225\n",
      "Train:\tP 0.952935393689902 \tR: 0.9651213441194773 \tF1: 0.9589896585305528\n",
      "Val:\tP 0.452880859375 \tR: 0.5296973158195317 \tF1: 0.48828639115556727\n",
      "epoch 14: 0.020375036\n",
      "Train:\tP 0.958925993057049 \tR: 0.966228138059124 \tF1: 0.9625632169729863\n",
      "Val:\tP 0.457275390625 \tR: 0.5227463019815797 \tF1: 0.48782393540825625\n",
      "epoch 15: 0.019253656\n",
      "Train:\tP 0.9681730207981322 \tR: 0.9742789130367576 \tF1: 0.9712163703041695\n",
      "Val:\tP 0.473388671875 \tR: 0.5340126686863124 \tF1: 0.5018765368189466\n",
      "epoch 16: 0.01855374\n",
      "Train:\tP 0.9667598537679334 \tR: 0.968694206735209 \tF1: 0.967726063625321\n",
      "Val:\tP 0.4716796875 \tR: 0.5280131183383439 \tF1: 0.4982591876208898\n",
      "epoch 17: 0.01564791\n",
      "Train:\tP 0.9671285060366809 \tR: 0.9816339257873402 \tF1: 0.9743272310858699\n",
      "Val:\tP 0.44970703125 \tR: 0.5491949910554562 \tF1: 0.494496644295302\n",
      "epoch 18: 0.016637689\n",
      "Train:\tP 0.9626432367669197 \tR: 0.9726835325159088 \tF1: 0.967637340579934\n",
      "Val:\tP 0.454345703125 \tR: 0.5413030831879 \tF1: 0.49402707724980094\n",
      "epoch 19: 0.016014382\n",
      "Train:\tP 0.9684187889772972 \tR: 0.9691333353829127 \tF1: 0.9687759304219552\n",
      "Val:\tP 0.4755859375 \tR: 0.529923830250272 \tF1: 0.5012866700977869\n",
      "epoch 0: 0.017666234\n",
      "Train:\tP 0.9629811680132715 \tR: 0.9795318896284491 \tF1: 0.9711860205725616\n",
      "Val:\tP 0.460693359375 \tR: 0.5472737819025522 \tF1: 0.5002651113467657\n",
      "epoch 1: 0.01727242\n",
      "Train:\tP 0.964087124819514 \tR: 0.975474806502751 \tF1: 0.9697475356138562\n",
      "Val:\tP 0.474365234375 \tR: 0.5397222222222222 \tF1: 0.5049376299376299\n",
      "epoch 2: 0.015600682\n",
      "Train:\tP 0.9668520168351202 \tR: 0.9784548422198042 \tF1: 0.9726188268743433\n",
      "Val:\tP 0.470947265625 \tR: 0.5373259052924791 \tF1: 0.501951600312256\n",
      "epoch 3: 0.01587129\n",
      "Train:\tP 0.9746551565236091 \tR: 0.9759443829211271 \tF1: 0.9752993436726662\n",
      "Val:\tP 0.463134765625 \tR: 0.5278241513633835 \tF1: 0.49336801040312095\n",
      "epoch 4: 0.014421666\n",
      "Train:\tP 0.9713680071272772 \tR: 0.9804037084121423 \tF1: 0.9758649424400481\n",
      "Val:\tP 0.461181640625 \tR: 0.5384834663625998 \tF1: 0.49684376643871647\n",
      "epoch 5: 0.014606407\n",
      "Train:\tP 0.9744708303892353 \tR: 0.9768415865976842 \tF1: 0.9756547683127509\n",
      "Val:\tP 0.474853515625 \tR: 0.528963829208594 \tF1: 0.500450276598482\n",
      "epoch 6: 0.01450939\n",
      "Train:\tP 0.9721360326871679 \tR: 0.9793265659816787 \tF1: 0.9757180518939921\n",
      "Val:\tP 0.450927734375 \tR: 0.5441956393635828 \tF1: 0.49319092122830444\n",
      "epoch 7: 0.014457093\n",
      "Train:\tP 0.9746551565236091 \tR: 0.9746850998463902 \tF1: 0.9746701279550237\n",
      "Val:\tP 0.455078125 \tR: 0.5243319268635724 \tF1: 0.4872565677689191\n",
      "epoch 8: 0.014428706\n",
      "Train:\tP 0.9715216122392554 \tR: 0.9826611149089554 \tF1: 0.9770596141071788\n",
      "Val:\tP 0.459716796875 \tR: 0.5512295081967213 \tF1: 0.5013312034078807\n",
      "epoch 9: 0.014279017\n",
      "Train:\tP 0.9741636201652791 \tR: 0.9857928933378929 \tF1: 0.9799437559875152\n",
      "Val:\tP 0.44873046875 \tR: 0.5506291192330737 \tF1: 0.49448479956954533\n",
      "epoch 10: 0.013045565\n",
      "Train:\tP 0.9807071979355473 \tR: 0.9836686901056914 \tF1: 0.9821857116485139\n",
      "Val:\tP 0.470458984375 \tR: 0.5426640382990707 \tF1: 0.5039884922191709\n",
      "epoch 11: 0.0118876975\n",
      "Train:\tP 0.9804307087339866 \tR: 0.9866749111145463 \tF1: 0.983542899408284\n",
      "Val:\tP 0.4501953125 \tR: 0.5519305597126609 \tF1: 0.49589888395858545\n",
      "epoch 12: 0.011581678\n",
      "Train:\tP 0.979662683174096 \tR: 0.9831966454954677 \tF1: 0.9814264830345465\n",
      "Val:\tP 0.462158203125 \tR: 0.5329391891891891 \tF1: 0.4950313807531381\n",
      "epoch 13: 0.012429196\n",
      "Train:\tP 0.9779115848975454 \tR: 0.9830152553887962 \tF1: 0.9804567785255571\n",
      "Val:\tP 0.47265625 \tR: 0.5484419263456091 \tF1: 0.5077366902701285\n",
      "epoch 14: 0.01478375\n",
      "Train:\tP 0.9689717673804185 \tR: 0.9834128394599819 \tF1: 0.9761388957662788\n",
      "Val:\tP 0.457275390625 \tR: 0.5576064304852635 \tF1: 0.5024815560026827\n",
      "epoch 15: 0.015047655\n",
      "Train:\tP 0.9774200485392154 \tR: 0.9879518072289156 \tF1: 0.9826577098293569\n",
      "Val:\tP 0.455078125 \tR: 0.5509902453443689 \tF1: 0.4984623612782457\n",
      "epoch 16: 0.011894563\n",
      "Train:\tP 0.9728733372246628 \tR: 0.9809801127563348 \tF1: 0.9769099069918098\n",
      "Val:\tP 0.460205078125 \tR: 0.5455861070911722 \tF1: 0.49927161965302613\n",
      "epoch 17: 0.012583674\n",
      "Train:\tP 0.9807379189579429 \tR: 0.9811599102560162 \tF1: 0.9809488692232055\n",
      "Val:\tP 0.463623046875 \tR: 0.5355329949238579 \tF1: 0.4969903166710285\n",
      "epoch 18: 0.012938839\n",
      "Train:\tP 0.9782187951215017 \tR: 0.9768982972848597 \tF1: 0.9775581002670924\n",
      "Val:\tP 0.476318359375 \tR: 0.5340815767862032 \tF1: 0.5035488450122596\n",
      "epoch 19: 0.014221118\n",
      "Train:\tP 0.9782495161438973 \tR: 0.9849670574406879 \tF1: 0.981596794081381\n",
      "Val:\tP 0.45849609375 \tR: 0.5451378809869376 \tF1: 0.4980771780930911\n",
      "epoch 0: 0.011599159\n",
      "Train:\tP 0.9806457558907561 \tR: 0.9806156303760137 \tF1: 0.9806306929020169\n",
      "Val:\tP 0.4833984375 \tR: 0.5336927223719676 \tF1: 0.5073020753266717\n",
      "epoch 1: 0.011547034\n",
      "Train:\tP 0.9845780467573961 \tR: 0.9796423658872077 \tF1: 0.9821040051481628\n",
      "Val:\tP 0.470703125 \tR: 0.5283639353247465 \tF1: 0.49786959328599095\n",
      "epoch 2: 0.0117955\n",
      "Train:\tP 0.9831648797271973 \tR: 0.975641729162856 \tF1: 0.979388857435772\n",
      "Val:\tP 0.475830078125 \tR: 0.5236432025792584 \tF1: 0.4985929905346636\n",
      "epoch 3: 0.012548801\n",
      "Train:\tP 0.9819974808761636 \tR: 0.9824502089992624 \tF1: 0.9822237927696775\n",
      "Val:\tP 0.47119140625 \tR: 0.547207258293167 \tF1: 0.5063623245441427\n",
      "epoch 4: 0.0129099265\n",
      "Train:\tP 0.9716444963288379 \tR: 0.9802876270766179 \tF1: 0.975946925865926\n",
      "Val:\tP 0.451904296875 \tR: 0.5444117647058824 \tF1: 0.493863393810032\n",
      "epoch 5: 0.012644889\n",
      "Train:\tP 0.9802156615772173 \tR: 0.9842371521993954 \tF1: 0.9822222906309163\n",
      "Val:\tP 0.4794921875 \tR: 0.548144013396595 \tF1: 0.5115249381429873\n",
      "epoch 6: 0.009006334\n",
      "Train:\tP 0.9892476421615312 \tR: 0.9911354612330328 \tF1: 0.9901906519065191\n",
      "Val:\tP 0.46337890625 \tR: 0.5466589861751152 \tF1: 0.501585623678647\n",
      "epoch 7: 0.009157678\n",
      "Train:\tP 0.9759147184418298 \tR: 0.9896878310175089 \tF1: 0.9827530201549909\n",
      "Val:\tP 0.43798828125 \tR: 0.5525100092392978 \tF1: 0.4886286259022198\n",
      "epoch 8: 0.010949931\n",
      "Train:\tP 0.9823046911001199 \tR: 0.987888899187444 \tF1: 0.9850888813580211\n",
      "Val:\tP 0.476318359375 \tR: 0.5452766908887646 \tF1: 0.5084701589783684\n",
      "epoch 9: 0.012219955\n",
      "Train:\tP 0.956867684556542 \tR: 0.9682603829893062 \tF1: 0.9625303233980746\n",
      "Val:\tP 0.456787109375 \tR: 0.541534008683068 \tF1: 0.49556350152297707\n",
      "epoch 10: 0.01588239\n",
      "Train:\tP 0.9839943473318792 \tR: 0.9894964473277726 \tF1: 0.986737727391753\n",
      "Val:\tP 0.46240234375 \tR: 0.555262386396951 \tF1: 0.5045957106700413\n",
      "epoch 11: 0.008034911\n",
      "Train:\tP 0.9916131608859943 \tR: 0.9916436251920123 \tF1: 0.9916283928050261\n",
      "Val:\tP 0.468994140625 \tR: 0.5491709548313322 \tF1: 0.5059257308401369\n",
      "epoch 12: 0.005016629\n",
      "Train:\tP 0.9959141040213818 \tR: 0.9949054750797938 \tF1: 0.9954095340446765\n",
      "Val:\tP 0.48779296875 \tR: 0.5392712550607287 \tF1: 0.5122420202538135\n",
      "epoch 13: 0.0043318714\n",
      "Train:\tP 0.9868821234370679 \tR: 0.9951672862453531 \tF1: 0.991007388440715\n",
      "Val:\tP 0.446044921875 \tR: 0.573086574654956 \tF1: 0.5016474464579902\n",
      "epoch 14: 0.009012549\n",
      "Train:\tP 0.9828883905256367 \tR: 0.9889036565388063 \tF1: 0.9858868482682116\n",
      "Val:\tP 0.4599609375 \tR: 0.5413793103448276 \tF1: 0.4973600844772967\n",
      "epoch 15: 0.011889511\n",
      "Train:\tP 0.9842401155110442 \tR: 0.9830924545091903 \tF1: 0.9836659502609764\n",
      "Val:\tP 0.476318359375 \tR: 0.5354006586169044 \tF1: 0.5041343669250646\n",
      "epoch 16: 0.009122044\n",
      "Train:\tP 0.9847009308469786 \tR: 0.9898094679307043 \tF1: 0.9872485908768904\n",
      "Val:\tP 0.46337890625 \tR: 0.5572519083969466 \tF1: 0.505998400426553\n",
      "epoch 17: 0.008565788\n",
      "Train:\tP 0.9874351018401892 \tR: 0.9871621621621621 \tF1: 0.9872986131375652\n",
      "Val:\tP 0.484130859375 \tR: 0.5479414202818458 \tF1: 0.5140635126377188\n",
      "epoch 18: 0.008105119\n",
      "Train:\tP 0.9894012472735093 \tR: 0.987399209001441 \tF1: 0.9883992143383256\n",
      "Val:\tP 0.480712890625 \tR: 0.5387140902872777 \tF1: 0.5080634756805572\n",
      "epoch 19: 0.010450509\n",
      "Train:\tP 0.9815366655402292 \tR: 0.978620436167606 \tF1: 0.9800763815395942\n",
      "Val:\tP 0.4736328125 \tR: 0.5422023476802683 \tF1: 0.5056033359395361\n",
      "epoch 0: 0.010196568\n",
      "Train:\tP 0.988110964332893 \tR: 0.9864139601925966 \tF1: 0.9872617330182019\n",
      "Val:\tP 0.472412109375 \tR: 0.5483139699631624 \tF1: 0.5075409836065573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: 0.009770058\n",
      "Train:\tP 0.9809836871371079 \tR: 0.987628355808487 \tF1: 0.984294807576715\n",
      "Val:\tP 0.455810546875 \tR: 0.5544995544995545 \tF1: 0.5003349859305909\n",
      "epoch 2: 0.009318443\n",
      "Train:\tP 0.9851003041381217 \tR: 0.9903026559604694 \tF1: 0.9876946296838182\n",
      "Val:\tP 0.458251953125 \tR: 0.5477093667931136 \tF1: 0.49900305729097444\n",
      "epoch 3: 0.009609735\n",
      "Train:\tP 0.9837793001751098 \tR: 0.9798959608323133 \tF1: 0.9818337906823443\n",
      "Val:\tP 0.488525390625 \tR: 0.5260252365930599 \tF1: 0.5065822784810126\n",
      "epoch 4: 0.011988357\n",
      "Train:\tP 0.9842093944886486 \tR: 0.9776021482408227 \tF1: 0.9808946449894369\n",
      "Val:\tP 0.484619140625 \tR: 0.54028307022319 \tF1: 0.510939510939511\n",
      "epoch 5: 0.011553955\n",
      "Train:\tP 0.9829805535928235 \tR: 0.9850686534080414 \tF1: 0.9840234957636891\n",
      "Val:\tP 0.475341796875 \tR: 0.55218377765173 \tF1: 0.510889530307006\n",
      "epoch 6: 0.009857952\n",
      "Train:\tP 0.9789560996589967 \tR: 0.9815191277028276 \tF1: 0.9802359382930618\n",
      "Val:\tP 0.46826171875 \tR: 0.5541750939034961 \tF1: 0.5076088394865688\n",
      "epoch 7: 0.012331579\n",
      "Train:\tP 0.9837485791527142 \tR: 0.9800153022188217 \tF1: 0.9818783920522491\n",
      "Val:\tP 0.48388671875 \tR: 0.5440570958001647 \tF1: 0.512210879958651\n",
      "epoch 8: 0.010671469\n",
      "Train:\tP 0.9870357285490461 \tR: 0.9879766297662976 \tF1: 0.9875059550337324\n",
      "Val:\tP 0.468994140625 \tR: 0.5555234239444766 \tF1: 0.5086047127349749\n",
      "epoch 9: 0.0095717935\n",
      "Train:\tP 0.9845473257350005 \tR: 0.9829468776837198 \tF1: 0.9837464507712377\n",
      "Val:\tP 0.46435546875 \tR: 0.5315818893236445 \tF1: 0.49569976544175137\n",
      "epoch 10: 0.010597929\n",
      "Train:\tP 0.9795705201069091 \tR: 0.9856873473677703 \tF1: 0.9826194144838213\n",
      "Val:\tP 0.46337890625 \tR: 0.5551330798479087 \tF1: 0.5051230871590152\n",
      "epoch 11: 0.012430817\n",
      "Train:\tP 0.9820282018985592 \tR: 0.9853884093711467 \tF1: 0.9837054361373113\n",
      "Val:\tP 0.46484375 \tR: 0.5504481063891298 \tF1: 0.5040370615486433\n",
      "epoch 12: 0.011613464\n",
      "Train:\tP 0.9822739700777242 \tR: 0.9827570308898109 \tF1: 0.9825154411086869\n",
      "Val:\tP 0.457763671875 \tR: 0.5346449957228401 \tF1: 0.49322635801657244\n",
      "epoch 13: 0.009989366\n",
      "Train:\tP 0.9671285060366809 \tR: 0.989128727181324 \tF1: 0.9780049085091181\n",
      "Val:\tP 0.43505859375 \tR: 0.5728061716489875 \tF1: 0.4945192174275011\n",
      "epoch 14: 0.010450755\n",
      "Train:\tP 0.9858376086756168 \tR: 0.989882164229749 \tF1: 0.9878557465868338\n",
      "Val:\tP 0.466064453125 \tR: 0.5518936108701937 \tF1: 0.5053606882859034\n",
      "epoch 15: 0.011849964\n",
      "Train:\tP 0.9854689564068693 \tR: 0.9873191751308095 \tF1: 0.9863931981365601\n",
      "Val:\tP 0.457275390625 \tR: 0.5536506059710317 \tF1: 0.5008691001470785\n",
      "epoch 16: 0.009815973\n",
      "Train:\tP 0.9887868268255967 \tR: 0.9882100092109303 \tF1: 0.9884983338707943\n",
      "Val:\tP 0.4716796875 \tR: 0.5483962531933012 \tF1: 0.5071531697073106\n",
      "epoch 17: 0.0077697854\n",
      "Train:\tP 0.9803999877115911 \tR: 0.9931225493247028 \tF1: 0.9867202597201824\n",
      "Val:\tP 0.454345703125 \tR: 0.5765179677819083 \tF1: 0.508192244675041\n",
      "epoch 18: 0.0080304695\n",
      "Train:\tP 0.9863291450339468 \tR: 0.9894295663964991 \tF1: 0.9878769230769231\n",
      "Val:\tP 0.474365234375 \tR: 0.557372346528973 \tF1: 0.512529675547349\n",
      "epoch 19: 0.01244503\n",
      "Train:\tP 0.9829498325704279 \tR: 0.9802996415331352 \tF1: 0.9816229483049547\n",
      "Val:\tP 0.474365234375 \tR: 0.5377802380293385 \tF1: 0.5040861330911921\n",
      "epoch 0: 0.012195807\n",
      "Train:\tP 0.9919818131547418 \tR: 0.9876429925980302 \tF1: 0.9898076480956395\n",
      "Val:\tP 0.48046875 \tR: 0.5369713506139154 \tF1: 0.5071511403169694\n",
      "epoch 1: 0.0071544456\n",
      "Train:\tP 0.9810451291818991 \tR: 0.981195845879678 \tF1: 0.9811204817426301\n",
      "Val:\tP 0.47900390625 \tR: 0.5478916503769896 \tF1: 0.511137162954279\n",
      "epoch 2: 0.011082462\n",
      "Train:\tP 0.9849774200485392 \tR: 0.9943863784387309 \tF1: 0.989659536376825\n",
      "Val:\tP 0.447998046875 \tR: 0.5630561521939245 \tF1: 0.49898028552005436\n",
      "epoch 3: 0.0060593346\n",
      "Train:\tP 0.9915517188412031 \tR: 0.9949138435929842 \tF1: 0.9932299359921222\n",
      "Val:\tP 0.470703125 \tR: 0.5538638322321172 \tF1: 0.508908538999604\n",
      "epoch 4: 0.005348242\n",
      "Train:\tP 0.9933028171177537 \tR: 0.9902606352025972 \tF1: 0.9917793932701451\n",
      "Val:\tP 0.4814453125 \tR: 0.5395348837209303 \tF1: 0.5088375693458909\n",
      "epoch 5: 0.005995253\n",
      "Train:\tP 0.9913673927068293 \tR: 0.9896647959027203 \tF1: 0.9905153626569262\n",
      "Val:\tP 0.48193359375 \tR: 0.5381679389312977 \tF1: 0.508500772797527\n",
      "epoch 6: 0.007239753\n",
      "Train:\tP 0.9927498387146324 \tR: 0.9838336479327772 \tF1: 0.9882716332553481\n",
      "Val:\tP 0.487548828125 \tR: 0.5288665254237288 \tF1: 0.5073678861788617\n",
      "epoch 7: 0.008150995\n",
      "Train:\tP 0.9879880802433105 \tR: 0.9847510564027191 \tF1: 0.9863669125427471\n",
      "Val:\tP 0.474365234375 \tR: 0.5398721867185329 \tF1: 0.5050032488628978\n",
      "epoch 8: 0.0098985545\n",
      "Train:\tP 0.9907836932813124 \tR: 0.9857867709988997 \tF1: 0.9882789158380192\n",
      "Val:\tP 0.4853515625 \tR: 0.5348399246704332 \tF1: 0.5088954306924357\n",
      "epoch 9: 0.0073661385\n",
      "Train:\tP 0.9917974870203681 \tR: 0.9913406620401646 \tF1: 0.9915690219144002\n",
      "Val:\tP 0.46728515625 \tR: 0.5415959252971138 \tF1: 0.5017038007863697\n",
      "epoch 10: 0.008456207\n",
      "Train:\tP 0.9848545359589567 \tR: 0.9882548783871266 \tF1: 0.9865517771964917\n",
      "Val:\tP 0.468994140625 \tR: 0.5523289246693502 \tF1: 0.507261684710853\n",
      "epoch 11: 0.010251329\n",
      "Train:\tP 0.975976160486621 \tR: 0.9818884252820275 \tF1: 0.9789233660986656\n",
      "Val:\tP 0.461669921875 \tR: 0.5493898895990703 \tF1: 0.5017245953833909\n",
      "epoch 12: 0.010125492\n",
      "Train:\tP 0.9829498325704279 \tR: 0.9892100788375329 \tF1: 0.9860700197238659\n",
      "Val:\tP 0.4677734375 \tR: 0.5581124381007865 \tF1: 0.5089653340417054\n",
      "epoch 13: 0.010499586\n",
      "Train:\tP 0.9793247519277442 \tR: 0.9813748730104978 \tF1: 0.9803487406587323\n",
      "Val:\tP 0.464599609375 \tR: 0.5448038935012883 \tF1: 0.5015153511661615\n",
      "epoch 14: 0.012541161\n",
      "Train:\tP 0.9870357285490461 \tR: 0.9873390491994715 \tF1: 0.9871873655748786\n",
      "Val:\tP 0.475341796875 \tR: 0.5478334271243669 \tF1: 0.5090196078431374\n",
      "epoch 15: 0.010662708\n",
      "Train:\tP 0.9901692728334 \tR: 0.9894093811394892 \tF1: 0.9897891811383911\n",
      "Val:\tP 0.476318359375 \tR: 0.5477259966311061 \tF1: 0.5095325150169756\n",
      "epoch 16: 0.008298188\n",
      "Train:\tP 0.9750238087923566 \tR: 0.9777271186962817 \tF1: 0.9763735925675261\n",
      "Val:\tP 0.464599609375 \tR: 0.547783534830167 \tF1: 0.5027741083223249\n",
      "epoch 17: 0.010518506\n",
      "Train:\tP 0.9849466990261436 \tR: 0.9903011583011583 \tF1: 0.9876166712873117\n",
      "Val:\tP 0.455810546875 \tR: 0.5576463560334528 \tF1: 0.5016120365394949\n",
      "epoch 18: 0.006521678\n",
      "Train:\tP 0.9941322847224355 \tR: 0.9937354133398846 \tF1: 0.9939338094141136\n",
      "Val:\tP 0.474853515625 \tR: 0.553028148990617 \tF1: 0.5109680809142257\n",
      "epoch 19: 0.005196829\n",
      "Train:\tP 0.9919818131547418 \tR: 0.9901566955935114 \tF1: 0.9910684141063809\n",
      "Val:\tP 0.4775390625 \tR: 0.5428809325562032 \tF1: 0.5081179373944669\n",
      "epoch 0: 0.006833092\n",
      "Train:\tP 0.9896162944302787 \tR: 0.9919017120335016 \tF1: 0.9907576852691958\n",
      "Val:\tP 0.473388671875 \tR: 0.5560653857183826 \tF1: 0.5114070948173547\n",
      "epoch 1: 0.0061172615\n",
      "Train:\tP 0.9926576756474456 \tR: 0.9941236193582131 \tF1: 0.9933901066806039\n",
      "Val:\tP 0.468994140625 \tR: 0.5597319347319347 \tF1: 0.5103613177470776\n",
      "epoch 2: 0.005376517\n",
      "Train:\tP 0.9879880802433105 \tR: 0.9847510564027191 \tF1: 0.9863669125427471\n",
      "Val:\tP 0.474365234375 \tR: 0.5380780947106065 \tF1: 0.5042169456338395\n",
      "epoch 3: 0.008347366\n",
      "Train:\tP 0.9851003041381217 \tR: 0.986919454618202 \tF1: 0.9860090403124135\n",
      "Val:\tP 0.47265625 \tR: 0.5461212976022567 \tF1: 0.5067399555032064\n",
      "epoch 4: 0.008470322\n",
      "Train:\tP 0.9807379189579429 \tR: 0.990167798765547 \tF1: 0.9854303000370416\n",
      "Val:\tP 0.46337890625 \tR: 0.5716867469879519 \tF1: 0.511866235167206\n",
      "epoch 5: 0.011049515\n",
      "Train:\tP 0.9804307087339866 \tR: 0.9820598824506878 \tF1: 0.9812446193580125\n",
      "Val:\tP 0.46923828125 \tR: 0.5452482269503546 \tF1: 0.5043957485894239\n",
      "epoch 6: 0.01634987\n",
      "Train:\tP 0.9880188012657061 \tR: 0.9833363908762918 \tF1: 0.9856720351839648\n",
      "Val:\tP 0.4794921875 \tR: 0.5280989513310029 \tF1: 0.5026231605886117\n",
      "epoch 7: 0.0068830717\n",
      "Train:\tP 0.991060182482873 \tR: 0.9957712133839554 \tF1: 0.993410112705549\n",
      "Val:\tP 0.46044921875 \tR: 0.5551957609655579 \tF1: 0.503403176297878\n",
      "epoch 8: 0.0043431115\n",
      "Train:\tP 0.9956376148198212 \tR: 0.9956376148198212 \tF1: 0.9956376148198212\n",
      "Val:\tP 0.482177734375 \tR: 0.5481543158479045 \tF1: 0.5130536433303026\n",
      "epoch 9: 0.004723954\n",
      "Train:\tP 0.9918896500875549 \tR: 0.9929878517607258 \tF1: 0.9924384471152369\n",
      "Val:\tP 0.4794921875 \tR: 0.5566893424036281 \tF1: 0.5152151101783841\n",
      "epoch 10: 0.006862135\n",
      "Train:\tP 0.9918896500875549 \tR: 0.9917373141663595 \tF1: 0.9918134762775125\n",
      "Val:\tP 0.47802734375 \tR: 0.5443425076452599 \tF1: 0.5090341869231769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11: 0.00703427\n",
      "Train:\tP 0.9903843199901693 \tR: 0.9923353956967402 \tF1: 0.9913588978750884\n",
      "Val:\tP 0.471923828125 \tR: 0.5519703026841805 \tF1: 0.5088181100289549\n",
      "epoch 12: 0.008638781\n",
      "Train:\tP 0.9843937206230223 \tR: 0.9769207317073171 \tF1: 0.9806429893957246\n",
      "Val:\tP 0.479736328125 \tR: 0.5289367429340511 \tF1: 0.5031366022276277\n",
      "epoch 13: 0.012100804\n",
      "Train:\tP 0.9817209916746029 \tR: 0.992268281322776 \tF1: 0.9869664587065291\n",
      "Val:\tP 0.45703125 \tR: 0.554995552920249 \tF1: 0.5012719239523363\n",
      "epoch 14: 0.00725058\n",
      "Train:\tP 0.991060182482873 \tR: 0.9889941445169993 \tF1: 0.9900260856222187\n",
      "Val:\tP 0.479736328125 \tR: 0.5360065466448445 \tF1: 0.5063128059778407\n",
      "epoch 15: 0.0050875526\n",
      "Train:\tP 0.9954532886854475 \tR: 0.9935913160799705 \tF1: 0.9945214308733484\n",
      "Val:\tP 0.47998046875 \tR: 0.5349659863945578 \tF1: 0.5059837858705445\n",
      "epoch 16: 0.0051365574\n",
      "Train:\tP 0.9856225615188473 \tR: 0.9926363664490578 \tF1: 0.9891170304599827\n",
      "Val:\tP 0.455322265625 \tR: 0.5524289099526066 \tF1: 0.4991970021413276\n",
      "epoch 17: 0.008283988\n",
      "Train:\tP 0.9857454456084298 \tR: 0.9882044964582691 \tF1: 0.9869734393503636\n",
      "Val:\tP 0.47705078125 \tR: 0.5530710444381546 \tF1: 0.512255865775331\n",
      "epoch 18: 0.009737595\n",
      "Train:\tP 0.978925378636601 \tR: 0.979918814195215 \tF1: 0.9794218445035271\n",
      "Val:\tP 0.466552734375 \tR: 0.5333519397153224 \tF1: 0.49772105742935274\n",
      "epoch 19: 0.0123164775\n",
      "Train:\tP 0.9783416792110842 \tR: 0.980691651525883 \tF1: 0.9795152559055118\n",
      "Val:\tP 0.463134765625 \tR: 0.5373937677053824 \tF1: 0.49750852347233143\n",
      "epoch 0: 0.0147449095\n",
      "Train:\tP 0.9658689441184602 \tR: 0.9697119240022207 \tF1: 0.9677866190571468\n",
      "Val:\tP 0.455810546875 \tR: 0.5225300867618248 \tF1: 0.4868952927369931\n",
      "epoch 1: 0.017287925\n",
      "Train:\tP 0.9765291388897422 \tR: 0.9869900018630069 \tF1: 0.981731704680575\n",
      "Val:\tP 0.447021484375 \tR: 0.5441307578008915 \tF1: 0.49081892507706737\n",
      "epoch 2: 0.008893942\n",
      "Train:\tP 0.9842708365334398 \tR: 0.9920116419481686 \tF1: 0.9881260794473229\n",
      "Val:\tP 0.45361328125 \tR: 0.5437518290898449 \tF1: 0.49460934380407295\n",
      "epoch 3: 0.008035677\n",
      "Train:\tP 0.9927191176922368 \tR: 0.9898303008025485 \tF1: 0.9912726045676948\n",
      "Val:\tP 0.4658203125 \tR: 0.5241758241758242 \tF1: 0.4932781799379525\n",
      "epoch 4: 0.0070668743\n",
      "Train:\tP 0.9852231882277043 \tR: 0.9922648514851485 \tF1: 0.9887314824806155\n",
      "Val:\tP 0.4619140625 \tR: 0.5472953427827596 \tF1: 0.5009929829206937\n",
      "epoch 5: 0.006386144\n",
      "Train:\tP 0.9925347915578631 \tR: 0.9912557911207928 \tF1: 0.9918948790372097\n",
      "Val:\tP 0.464111328125 \tR: 0.5317482517482518 \tF1: 0.49563290314170255\n",
      "epoch 6: 0.0061083147\n",
      "Train:\tP 0.9906915302141255 \tR: 0.9910873440285205 \tF1: 0.9908893975940635\n",
      "Val:\tP 0.47216796875 \tR: 0.5414333706606943 \tF1: 0.5044340114762651\n",
      "epoch 7: 0.005845225\n",
      "Train:\tP 0.9936714693865012 \tR: 0.9908709371074963 \tF1: 0.9922692272294997\n",
      "Val:\tP 0.4736328125 \tR: 0.5359116022099447 \tF1: 0.5028512182477969\n",
      "epoch 8: 0.0055313995\n",
      "Train:\tP 0.9907529722589168 \tR: 0.9931939268886083 \tF1: 0.9919719479560765\n",
      "Val:\tP 0.460693359375 \tR: 0.5463231036479445 \tF1: 0.4998675496688741\n",
      "epoch 9: 0.006973349\n",
      "Train:\tP 0.9870050075266504 \tR: 0.9912378131556214 \tF1: 0.9891168819173992\n",
      "Val:\tP 0.466064453125 \tR: 0.5427921524026159 \tF1: 0.5015105740181269\n",
      "epoch 10: 0.007992157\n",
      "Train:\tP 0.9854996774292648 \tR: 0.9943585133752828 \tF1: 0.9899092760599888\n",
      "Val:\tP 0.445556640625 \tR: 0.5459168411606342 \tF1: 0.4906573464175293\n",
      "epoch 11: 0.0071808537\n",
      "Train:\tP 0.9781266320543147 \tR: 0.9908505274950985 \tF1: 0.984447467689073\n",
      "Val:\tP 0.44775390625 \tR: 0.5397292525014714 \tF1: 0.48945823325326926\n",
      "epoch 12: 0.0075767287\n",
      "Train:\tP 0.9901385518110043 \tR: 0.9923946177294701 \tF1: 0.9912653011010643\n",
      "Val:\tP 0.4580078125 \tR: 0.5420398728691129 \tF1: 0.4964933174540161\n",
      "epoch 13: 0.005207326\n",
      "Train:\tP 0.9944087739239962 \tR: 0.9951424970024902 \tF1: 0.9947755001690279\n",
      "Val:\tP 0.4638671875 \tR: 0.540386803185438 \tF1: 0.49921177088807145\n",
      "epoch 14: 0.0050610346\n",
      "Train:\tP 0.993272096095358 \tR: 0.9910191570881226 \tF1: 0.9921443476126182\n",
      "Val:\tP 0.46923828125 \tR: 0.5331484049930652 \tF1: 0.4991559537722374\n",
      "epoch 15: 0.006231089\n",
      "Train:\tP 0.9863291450339468 \tR: 0.9929485989979588 \tF1: 0.9896278030361408\n",
      "Val:\tP 0.446044921875 \tR: 0.5400532072125332 \tF1: 0.48856799037304455\n",
      "epoch 16: 0.0059087253\n",
      "Train:\tP 0.9916746029307856 \tR: 0.9886676875957121 \tF1: 0.9901688624407601\n",
      "Val:\tP 0.465087890625 \tR: 0.5239273927392739 \tF1: 0.49275737196068287\n",
      "epoch 17: 0.0058719125\n",
      "Train:\tP 0.9923197444010937 \tR: 0.989098814955446 \tF1: 0.9907066617592933\n",
      "Val:\tP 0.47705078125 \tR: 0.5322800326886407 \tF1: 0.5031543710570361\n",
      "epoch 18: 0.007132656\n",
      "Train:\tP 0.9824275751897024 \tR: 0.9909516283970128 \tF1: 0.9866711918793003\n",
      "Val:\tP 0.460693359375 \tR: 0.5515931014323298 \tF1: 0.5020619928162832\n",
      "epoch 19: 0.009050235\n",
      "Train:\tP 0.9831648797271973 \tR: 0.9778178373919154 \tF1: 0.9804840686274511\n",
      "Val:\tP 0.476806640625 \tR: 0.5220529270248596 \tF1: 0.49840500191399767\n",
      "epoch 0: 0.008957693\n",
      "Train:\tP 0.9920125341771374 \tR: 0.9906430236838876 \tF1: 0.9913273059388766\n",
      "Val:\tP 0.462646484375 \tR: 0.5266814897165092 \tF1: 0.4925916298414349\n",
      "epoch 1: 0.0068739853\n",
      "Train:\tP 0.9805843138459648 \tR: 0.9913964467635731 \tF1: 0.9859607394937216\n",
      "Val:\tP 0.4443359375 \tR: 0.5431214562817069 \tF1: 0.48878743118034107\n",
      "epoch 2: 0.0070047583\n",
      "Train:\tP 0.9915209978188074 \tR: 0.9902736867943054 \tF1: 0.990896949787391\n",
      "Val:\tP 0.46142578125 \tR: 0.5334462320067739 \tF1: 0.49482916612122\n",
      "epoch 3: 0.005849449\n",
      "Train:\tP 0.993272096095358 \tR: 0.9905940745733631 \tF1: 0.9919312778033439\n",
      "Val:\tP 0.469970703125 \tR: 0.5383109619686801 \tF1: 0.5018248175182483\n",
      "epoch 4: 0.005684181\n",
      "Train:\tP 0.9912445086172468 \tR: 0.9906358416996714 \tF1: 0.9909400816928227\n",
      "Val:\tP 0.46826171875 \tR: 0.5356045797263335 \tF1: 0.4996743519604013\n",
      "epoch 5: 0.015436416\n",
      "Train:\tP 0.9838100211975055 \tR: 0.9827533296507702 \tF1: 0.9832813915286243\n",
      "Val:\tP 0.456787109375 \tR: 0.5319874893375035 \tF1: 0.49152765007224486\n",
      "epoch 6: 0.009972492\n",
      "Train:\tP 0.9905993671469386 \tR: 0.9870213352107503 \tF1: 0.9888071143820915\n",
      "Val:\tP 0.46826171875 \tR: 0.5168418216114254 \tF1: 0.491353913154861\n",
      "epoch 7: 0.007582134\n",
      "Train:\tP 0.9829191115480324 \tR: 0.9889345655735171 \tF1: 0.985917663009984\n",
      "Val:\tP 0.446533203125 \tR: 0.5333916593759114 \tF1: 0.4861129568106312\n",
      "epoch 8: 0.009322793\n",
      "Train:\tP 0.9835335319959448 \tR: 0.991145784960218 \tF1: 0.9873249861222477\n",
      "Val:\tP 0.4443359375 \tR: 0.5450733752620545 \tF1: 0.48957632817753866\n",
      "epoch 9: 0.00860953\n",
      "Train:\tP 0.9913981137292249 \tR: 0.985253709470599 \tF1: 0.9883163616874666\n",
      "Val:\tP 0.47509765625 \tR: 0.5232589405754235 \tF1: 0.49801663467690344\n",
      "epoch 10: 0.006622826\n",
      "Train:\tP 0.9866670762802986 \tR: 0.9926441044660794 \tF1: 0.9896465658028534\n",
      "Val:\tP 0.450927734375 \tR: 0.5355175413163236 \tF1: 0.4895957587806494\n",
      "epoch 11: 0.007972517\n",
      "Train:\tP 0.987619427974563 \tR: 0.990632318501171 \tF1: 0.9891235789117426\n",
      "Val:\tP 0.454833984375 \tR: 0.5384393063583816 \tF1: 0.49311805187930124\n",
      "epoch 12: 0.008497061\n",
      "Train:\tP 0.9852539092500998 \tR: 0.9865571551618063 \tF1: 0.9859051015232327\n",
      "Val:\tP 0.4541015625 \tR: 0.5263157894736842 \tF1: 0.4875491480996068\n",
      "epoch 13: 0.008262767\n",
      "Train:\tP 0.9882338484224755 \tR: 0.987475442043222 \tF1: 0.9878544996698759\n",
      "Val:\tP 0.459228515625 \tR: 0.5243936437134096 \tF1: 0.48965247950019525\n",
      "epoch 14: 0.0106846085\n",
      "Train:\tP 0.9730576633590365 \tR: 0.9754550214037141 \tF1: 0.9742548675832795\n",
      "Val:\tP 0.45947265625 \tR: 0.5355719977233921 \tF1: 0.4946123521681997\n",
      "epoch 15: 0.0153683955\n",
      "Train:\tP 0.9876808700193542 \tR: 0.9847463856897819 \tF1: 0.9862114449608121\n",
      "Val:\tP 0.460205078125 \tR: 0.5323354984467664 \tF1: 0.4936493387455807\n",
      "epoch 16: 0.010172771\n",
      "Train:\tP 0.9853460723172868 \tR: 0.9833823890115281 \tF1: 0.9843632513388679\n",
      "Val:\tP 0.4619140625 \tR: 0.5292307692307693 \tF1: 0.49328640333724416\n",
      "epoch 17: 0.01635834\n",
      "Train:\tP 0.964824429357009 \tR: 0.9638472870120305 \tF1: 0.9643356106547939\n",
      "Val:\tP 0.460205078125 \tR: 0.528603477285474 \tF1: 0.492038632210911\n",
      "epoch 18: 0.029943123\n",
      "Train:\tP 0.9436883659488188 \tR: 0.9511689115962223 \tF1: 0.9474138728680257\n",
      "Val:\tP 0.445068359375 \tR: 0.5115039281705949 \tF1: 0.4759791122715405\n",
      "epoch 19: 0.025727859\n",
      "Train:\tP 0.9694633037387484 \tR: 0.9744326076887447 \tF1: 0.9719416040409018\n",
      "Val:\tP 0.455322265625 \tR: 0.5256482525366404 \tF1: 0.4879644165358451\n"
     ]
    }
   ],
   "source": [
    "loss_hist = []\n",
    "for i in range(10):\n",
    "    epoch_losses = train_epoches(tomodel, 20, 32)\n",
    "    loss_hist.append(epoch_losses)\n",
    "    bn = (i+1)*50\n",
    "    torch.save(tomodel.encoder, \"saved/encoder_{}.pth\".format(bn))\n",
    "    torch.save(tomodel.classifier, \"saved/rnn_cls_{}.pth\".format(bn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
