{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** The notebook requires the python files we submitted. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition\n",
    "\n",
    "Talk about how we got our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "First we need to preprocess our data. For details see common.py. The following code assumes tmdb_posters.pkl in ../data folder and glove.6B.300d.txt in ../local/glove. Results are stored in /tmp, and after that they should be moved to ../local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from common import Data, Split, Batches, encode_y, Vocab\n",
    "\n",
    "if False:\n",
    "    # load pickled data\n",
    "    data_file = \"../data/tmdb_posters.pkl\"\n",
    "    data = pickle.load(open(data_file, 'rb'))\n",
    "\n",
    "\n",
    "    # get overviews from data\n",
    "    OVERVIEWS = Data(np.array([d['overview'] for d in data]))\n",
    "    # get title from data\n",
    "    TITLES = Data(np.array([d['title'] for d in data]))\n",
    "\n",
    "    OVERVIEWS.save(\"/tmp/overviews.pkl\")\n",
    "    TITLES.save(\"/tmp/titles.pkl\")\n",
    "\n",
    "    # get genres, encode as 'one'-hot vectors\n",
    "    GENRES = Data(encode_y(np.array([d['genre_ids'] for d in data])))\n",
    "    GENRES.save(\"/tmp/genres.pkl\")\n",
    "\n",
    "    # create train-val-test split\n",
    "    train, val, test = OVERVIEWS.create_splits(0.8,0.1)\n",
    "    train.save(\"/tmp/train.pkl\")\n",
    "    val.save(\"/tmp/val.pkl\")\n",
    "    test.save(\"/tmp/test.pkl\")\n",
    "\n",
    "    # create vocab, this is to support fine-tuning of embeddings (otherwise don't call add_sentences)\n",
    "    # during this step, all punctuations are removed and all words are converted to lower cases.\n",
    "    vocab = Vocab()\n",
    "    vocab.initialize_glove(\"../local/glove/glove.6B.300d.txt\")\n",
    "    vocab.add_sentences(train.get_data(OVERVIEWS))\n",
    "    vocab.add_sentences(train.get_data(TITLES))\n",
    "    vocab.save(\"/tmp/vocab.pkl\")\n",
    "\n",
    "    # create embedding layer, for now we freeze the embedding layer. (default is freeze=True)\n",
    "    embedding = vocab.create_pytorch_embeddings()\n",
    "    torch.save(embedding, \"/tmp/embedding.pth\")\n",
    "\n",
    "    # encode data as indices\n",
    "    OVERVIEWS_ENCODED = Data(vocab.encode_sentences(OVERVIEWS.data))\n",
    "    TITLES_ENCODED = Data(vocab.encode_sentences(TITLES.data))\n",
    "\n",
    "    OVERVIEWS_ENCODED.save(\"/tmp/overviews_encoded.pkl\")\n",
    "    TITLES_ENCODED.save(\"/tmp/titles_encoded.pkl\")\n",
    "\n",
    "    del OVERVIEWS_ENCODED, TITLES_ENCODED, vocab, embedding, train, val, test, GENRES, TITLES, OVERVIEWS, data, data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved preprocessed data\n",
    "from common import load_data, load_split\n",
    "GENRES = load_data(\"../local/genres.pkl\")\n",
    "train = load_split(\"../local/train.pkl\")\n",
    "val = load_split(\"../local/val.pkl\")\n",
    "test = load_split(\"../local/test.pkl\")\n",
    "OVERVIEWS = load_data(\"../local/overviews_encoded.pkl\")\n",
    "OVERVIEWS_ENCODED = OVERVIEWS\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def report(Y_true, Y_pred):\n",
    "    print(\"acc:\", accuracy_score(Y_true, Y_pred), \"\\tf1:\",f1_score(Y_true, Y_pred, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM and NaiveBayes (Bag of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "    \n",
    "X_train = train.get_data(OVERVIEWS)\n",
    "X_val = val.get_data(OVERVIEWS)\n",
    "X_test = test.get_data(OVERVIEWS)\n",
    "Y_train = train.get_data(GENRES)\n",
    "Y_val = val.get_data(GENRES)\n",
    "Y_test = test.get_data(GENRES)\n",
    "\n",
    "X_train = [\" \".join([str(e) for e in x]) for x in X_train]\n",
    "X_val = [\" \".join([str(e) for e in x]) for x in X_val]\n",
    "X_test = [\" \".join([str(e) for e in x]) for x in X_test]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "cv = CountVectorizer()\n",
    "\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_val_cv = cv.transform(X_val)\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.3373333333333333 \tf1: 0.5013595752945745\n",
      "acc: 0.33 \tf1: 0.49223070845404265\n"
     ]
    }
   ],
   "source": [
    "svm = OneVsRestClassifier(LinearSVC())\n",
    "svm.fit(X_train_cv, Y_train)\n",
    "val_predict_svm = svm.predict(X_val_cv)\n",
    "test_predict_svm = svm.predict(X_test_cv)\n",
    "report(Y_val, val_predict_svm)\n",
    "report(Y_test, test_predict_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.185 \tf1: 0.4241896889275614\n",
      "acc: 0.188 \tf1: 0.42417035996108526\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(max_df=0.95, min_df=0.005)\n",
    "\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_val_cv = cv.transform(X_val)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "\n",
    "nb = OneVsRestClassifier(MultinomialNB())\n",
    "nb.fit(X_train_cv, Y_train)\n",
    "val_predict_nb = nb.predict(X_val_cv)\n",
    "test_predict_nb = nb.predict(X_test_cv)\n",
    "report(Y_val, val_predict_nb)\n",
    "report(Y_test, test_predict_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of SVM is better than NB in our experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_cv)\n",
    "X_val_tfidf = tfidf.transform(X_val_cv)\n",
    "X_test_tfidf = tfidf.transform(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.279 \tf1: 0.3320158102766798\n",
      "acc: 0.277 \tf1: 0.3219440891649918\n"
     ]
    }
   ],
   "source": [
    "svm = OneVsRestClassifier(LinearSVC())\n",
    "svm.fit(X_train_tfidf, Y_train)\n",
    "val_predict_svm = svm.predict(X_val_tfidf)\n",
    "test_predict_svm = svm.predict(X_test_tfidf)\n",
    "report(Y_val, val_predict_svm)\n",
    "report(Y_test, test_predict_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.24966666666666668 \tf1: 0.1397802197802198\n",
      "acc: 0.25133333333333335 \tf1: 0.14345991561181437\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(max_df=0.95, min_df=0.005)\n",
    "\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_val_cv = cv.transform(X_val)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_cv)\n",
    "X_val_tfidf = tfidf.transform(X_val_cv)\n",
    "X_test_tfidf = tfidf.transform(X_test_cv)\n",
    "\n",
    "nb = OneVsRestClassifier(MultinomialNB())\n",
    "nb.fit(X_train_tfidf, Y_train)\n",
    "val_predict_nb = nb.predict(X_val_tfidf)\n",
    "test_predict_nb = nb.predict(X_test_tfidf)\n",
    "report(Y_val, val_predict_nb)\n",
    "report(Y_test, test_predict_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tfidf doesn't improve the performance of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-Only Model\n",
    "\n",
    "The model is composed of an encoder and a classifier. The encoder definition is:\n",
    "```\n",
    "class Encoder2(torch.nn.Module):\n",
    "    def __init__(self, encoder, embedding, hidden_dim, input_channel, num_layers, bidirectional, dropout, cuda):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = embedding\n",
    "        self.bidirectional = bidirectional\n",
    "        self.cuda = cuda\n",
    "\n",
    "        self.encoder = encoder(input_size=input_channel, hidden_size=hidden_dim, batch_first=True,\n",
    "                                bidirectional=bidirectional, num_layers=num_layers, dropout=dropout)\n",
    "        \n",
    "        if cuda:\n",
    "            self.embedding.cuda()\n",
    "            self.encoder.cuda()\n",
    "\n",
    "    def forward(self, pack:Pack):\n",
    "        rev = pack.get_rev()\n",
    "        data = pack.get_pack(self.embedding, torch_var=True)\n",
    "        if self.cuda:\n",
    "            rev.cuda()\n",
    "        states_packed, _ = self.encoder(data) # (packed_sequence, hidden_state)\n",
    "        states, _ = torch.nn.utils.rnn.pad_packed_sequence(states_packed)\n",
    "        states = torch.cat([states[-1,:,:self.hidden_dim], states[0,:,self.hidden_dim:]], dim=1)\n",
    "        return states[rev, :]\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        pass\n",
    "```\n",
    "The classifier definition is:\n",
    "```\n",
    "class BRClassifier(torch.nn.Module):\n",
    "    def __init__(self, dims, num_class, encoding_size, cuda):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.classifiers = []\n",
    "        for i in range(num_class):\n",
    "            cls = MultiLayerFCReLUClassifier(dims, 1, encoding_size, cuda)\n",
    "            self.add_module(str(i), cls)\n",
    "            self.classifiers.append(cls)\n",
    "\n",
    "    def forward(self, encodings):\n",
    "        out = torch.stack([cls(encodings) for cls in self.classifiers])[:,:,0]\n",
    "        return torch.transpose(out,0,1)\n",
    "```\n",
    "\n",
    "where MultiLayerFCReLUClassifier is defined as:\n",
    "```\n",
    "class MultiLayerFCReLUClassifier(torch.nn.Module):\n",
    "    def __init__(self, dims, num_class, encoding_size, cuda):\n",
    "        super().__init__()\n",
    "        assert(len(dims)>0)\n",
    "        self.fc1 = torch.nn.Linear(encoding_size, dims[0])\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        if cuda:\n",
    "            self.fc1.cuda()\n",
    "            self.relu1.cuda()\n",
    "        self.fcs = []\n",
    "        self.relus = []\n",
    "        prev_dim = dims[0]\n",
    "        for dim in dims[1:]:\n",
    "            fc = torch.nn.Linear(prev_dim, dim)\n",
    "            relu = torch.nn.ReLU()\n",
    "            if cuda:\n",
    "                fc.cuda()\n",
    "                relu.cuda()\n",
    "            self.fcs.append(fc)\n",
    "            self.relus.append(relu)\n",
    "            prev_dim = dim\n",
    "        \n",
    "        self.out_fc = torch.nn.Linear(dims[-1], num_class)\n",
    "        if cuda:\n",
    "            self.out_fc.cuda()\n",
    "\n",
    "    def forward(self, encodings):\n",
    "        l_out = self.fc1(encodings)\n",
    "        l_out = self.relu1(l_out)\n",
    "        for i in range(len(self.fcs)):\n",
    "            l_out = self.fcs[i](l_out)\n",
    "            l_out = self.relus[i](l_out)\n",
    "        out = self.out_fc(l_out)\n",
    "        return out\n",
    "```\n",
    "\n",
    "The basic idea is encoder is a multi layer LSTM/GRU uni/bidirectional network and the classifier is a combinition of 19 binary classifiers. In our experiments, a 3-layer bidirectional LSTM performs best. It's easy to change to any combination of LSTM/GRU+uni/bidirectional+different hidden dim+different number of layers by changing the parameters of Encoder2 class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "embedding = torch.load('../local/embedding.pth').cuda()\n",
    "\n",
    "from cls import BRClassifier\n",
    "from torch_models import Encoder2\n",
    "from model import TextOnlyModel\n",
    "from train import train_epoches\n",
    "\n",
    "classifier = BRClassifier(dims=[1024, 512], num_class=19, encoding_size=1024, cuda=True)\n",
    "encoder = Encoder2(encoder=torch.nn.LSTM, embedding=embedding, input_channel=embedding.embedding_dim,\n",
    "                  hidden_dim=512, num_layers=3, cuda=True, bidirectional=True, dropout=0)\n",
    "\n",
    "# replace torch.nn.LSTM by torch.nn.GRU to use GRU\n",
    "# change num_layers, hidden_dim, bidirectional to experiment with different configs\n",
    "# dropout isn't very useful, we tried and it led to underfit.\n",
    "\n",
    "model = TextOnlyModel(encoder, classifier, OVERVIEWS_ENCODED, GENRES)\n",
    "loss = torch.nn.BCEWithLogitsLoss().cuda()\n",
    "adam = torch.optim.Adam(filter(lambda p:p.requires_grad, model.parameters()))\n",
    "\n",
    "optimizer = adam\n",
    "scheduler = None\n",
    "\n",
    "loss_hist = []\n",
    "save_per_epoch = 10\n",
    "n_epochs = 0 # change this to train\n",
    "\n",
    "for i in range(int(n_epochs/save_per_epoch)): \n",
    "    epoch_losses = train_epoches(n_epochs=save_per_epoch, model=model, train=train, loss=loss, val=val,\n",
    "                  batch_size=32, optimizer=optimizer, scheduler=scheduler)\n",
    "    loss_hist.append(epoch_losses)\n",
    "    bn = (i+1)*save_per_epoch\n",
    "    torch.save(model.encoder, \"/tmp/encoder_{}_{}.pth\".format(bn, str(epoch_losses[1][1][-1])[:4]))\n",
    "    torch.save(model.classifier, \"/tmp/cls_{}_{}.pth\".format(bn, str(epoch_losses[1][1][-1])[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import evaluate, inference\n",
    "encoder = torch.load(\"./saved/overview-lstm2/encoder_70_0.53.pth\")\n",
    "encoder.encoder.cuda()\n",
    "classifier = torch.load(\"./saved/overview-lstm2/cls_70_0.53.pth\").cuda()\n",
    "model = TextOnlyModel(encoder, classifier, OVERVIEWS_ENCODED, GENRES)\n",
    "Yp_val, Yt_val = inference(split=val, model=model, batch_size=128)\n",
    "Yp_test, Yt_test = inference(split=test, model=model, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.3556666666666667 \tf1: 0.5327067191667725\n",
      "acc: 0.3486666666666667 \tf1: 0.5147591921284308\n"
     ]
    }
   ],
   "source": [
    "report(Yt_val, Yp_val)\n",
    "report(Yt_test, Yp_test)\n",
    "del model, encoder, classifier, optimizer, scheduler, adam, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our RNN performs better than all previous models. But what about we do something more interesting? Like using the posters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poster-Only Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to preprocess the posters. We assume posters are in ../local/posters. We need to copy posters.npy from tmp to ../local after preprocessing. We essentially convert images into matrices, and apply the transformation required by the torchvision models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "# For efficiency we load all images into RAM and do the preprocessing. This requires A LOT OF RAM space.\n",
    "# Instead the images could be processes individually and combined afterwards.\n",
    "if False:\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    toTensor = transforms.ToTensor()\n",
    "    preprocess = transforms.Compose([toTensor, normalize])\n",
    "\n",
    "    images_list = []\n",
    "\n",
    "    image_folder = \"../local/posters/\"\n",
    "    for i in range(30000):\n",
    "        f = os.path.join(image_folder, \"{}.jpg\".format(i))\n",
    "        I = cv2.imread(f)\n",
    "        assert(I is not None)\n",
    "        I = preprocess(I)\n",
    "        images_list.append(I.numpy())\n",
    "\n",
    "    images = np.stack(images_list)\n",
    "\n",
    "    POSTERS = Data(images)\n",
    "    assert(len(POSTERS)==30000)\n",
    "    POSTERS.save(\"/tmp/posters.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of poster-only model is very similar to TextOnlyModel, except for that now the encoder is replaced by CNN. We tried both VGG16 and RESNET152 as our encoder, and found RES152 is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet152, vgg16\n",
    "from model import PosterOnlyModel\n",
    "\n",
    "POSTERS = load_data(\"../local/posters.npy\")\n",
    "\n",
    "if True:\n",
    "    MODEL = resnet152(pretrained=True)\n",
    "    # Freeze base layers\n",
    "    for child in list(MODEL.children())[:-3]:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "    MODEL = torch.nn.Sequential(*list(MODEL.children())[:-1]).cuda()\n",
    "\n",
    "    # Conv4, turn off grad in first 2 blocks\n",
    "    for child in list(list(MODEL.children())[-3].children())[:2]:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "else:\n",
    "    # in order to use VGG16, just use the following code instead of the code above\n",
    "    MODEL = vgg16(pretrained=True)\n",
    "    # Freeze base layers (except for the last three conv layers)\n",
    "    for child in list(MODEL.features.children())[:-7]:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "    MODEL = MODEL.features.cuda()\n",
    "    \n",
    "classifier = BRClassifier(dims=[1024, 512], num_class=19, encoding_size=2048, cuda=True)\n",
    "\n",
    "model = PosterOnlyModel(MODEL, classifier, POSTERS, GENRES)\n",
    "\n",
    "adam = torch.optim.Adam(filter(lambda p:p.requires_grad, model.parameters()))\n",
    "\n",
    "optimizer = adam\n",
    "scheduler = None\n",
    "\n",
    "loss = torch.nn.BCEWithLogitsLoss().cuda()\n",
    "\n",
    "n_epochs = 0 # change this to train\n",
    "save_per_epoch = 10\n",
    "for i in range(int(n_epochs/save_per_epoch)): \n",
    "    epoch_losses = train_epoches(n_epochs=save_per_epoch, model=model, train=train, loss=loss, val=val,\n",
    "                  batch_size=16, optimizer=optimizer, scheduler=scheduler)\n",
    "    loss_hist.append(epoch_losses)\n",
    "    bn = (i+1)*save_per_epoch\n",
    "    torch.save(model.encoder, \"/tmp/cnn_encoder_{}_{}.pth\".format(bn, str(epoch_losses[1][1][-1])[:4]))\n",
    "    torch.save(model.classifier, \"/tmp/cnn_cls_{}_{}.pth\".format(bn, str(epoch_losses[1][1][-1])[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = torch.load(\"./saved/poster-res2/encoder_80_0.45.pth\")\n",
    "encoder.cuda()\n",
    "classifier = torch.load(\"./saved/poster-res2/cls_80_0.45.pth\").cuda()\n",
    "model = PosterOnlyModel(encoder, classifier, POSTERS, GENRES)\n",
    "Yp_val, Yt_val = inference(split=val, model=model, batch_size=32)\n",
    "Yp_test, Yt_test = inference(split=test, model=model, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.31966666666666665 \tf1: 0.45208568207440814\n",
      "acc: 0.31066666666666665 \tf1: 0.4304740083058857\n"
     ]
    }
   ],
   "source": [
    "report(Yt_val, Yp_val)\n",
    "report(Yt_test, Yp_test)\n",
    "del model, MODEL, classifier, optimizer, scheduler, adam, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The poster-only model is worse than text-only model and several traditional models. But it's not surprising because inferring genre from poster is harder (even for humans) than from overview text. But what if we combine the poster model with text model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is simple, the CNN and RNN operates independently, and the encodings from both networks are then stacked and fed to a classifier.\n",
    "\n",
    "We wanted to train the combined model, but the GPU RAM is too small! So instead we fixed RNN and CNN, and only train the classifier.\n",
    "\n",
    "The combined encoder is simple as \n",
    "\n",
    "```\n",
    "class TextPosterCombinedEncoder(torch.nn.Module):\n",
    "    def __init__(self, text_encoder, poster_encoder):\n",
    "        super().__init__()\n",
    "        self.text_encoder = text_encoder\n",
    "        self.poster_encoder = poster_encoder\n",
    "        \n",
    "    def forward(self, text_pack, posters):\n",
    "        poster_encodings = self.poster_encoder(posters).view(len(posters),-1)\n",
    "        text_encodings = self.text_encoder(text_pack)\n",
    "        return poster_encodings, text_encodings\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_models import TextPosterCombinedEncoder\n",
    "from model import TextPosterCombinedModel\n",
    "\n",
    "text_encoder = torch.load(\"./saved/overview-lstm2/encoder_70_0.53.pth\")\n",
    "posters_encoder = torch.load(\"./saved/poster-res2/encoder_80_0.45.pth\")\n",
    "\n",
    "encoder = TextPosterCombinedEncoder(text_encoder, posters_encoder).cuda()\n",
    "\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "classifier = BRClassifier(dims=[1024, 512], num_class=19, encoding_size=2048+1024, cuda=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad, classifier.parameters()))\n",
    "loss = torch.nn.BCEWithLogitsLoss().cuda()\n",
    "\n",
    "scheduler=None\n",
    "\n",
    "model = TextPosterCombinedModel(encoder, classifier, OVERVIEWS_ENCODED, POSTERS, GENRES)\n",
    "\n",
    "n_epochs = 0 # change this to train\n",
    "save_per_epoch = 4\n",
    "for i in range(int(n_epochs/save_per_epoch)): \n",
    "    epoch_losses = train_epoches(n_epochs=save_per_epoch, model=model, train=train, loss=loss, val=val,\n",
    "                  batch_size=32, optimizer=optimizer, scheduler=scheduler)\n",
    "    bn = (i+1)*save_per_epoch\n",
    "    torch.save(model.classifier, \"/tmp/cbn_cls_{}_{}.pth\".format(bn, str(epoch_losses[1][1][-1])[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = torch.load(\"./saved/cbn/cls_4_0.54.pth\").cuda()\n",
    "model = TextPosterCombinedModel(encoder, classifier, OVERVIEWS_ENCODED, POSTERS, GENRES)\n",
    "Yp_val, Yt_val = inference(split=val, model=model, batch_size=32)\n",
    "Yp_test, Yt_test = inference(split=test, model=model, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.3973333333333333 \tf1: 0.5420451215939057\n",
      "acc: 0.37933333333333336 \tf1: 0.5186186186186187\n"
     ]
    }
   ],
   "source": [
    "report(Yt_val, Yp_val)\n",
    "report(Yt_test, Yp_test)\n",
    "del model, encoder, classifier, optimizer, scheduler, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is slightly better than TextOnlyModel thus having the best performance. The result could be better if we don't fix some layers of the RNN and CNN, but it requires more GPU RAM. Maybe training on a more powerful GPU or multiple GPUs is a possible future direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
